# 如果您是一名开发者，建议阅读以下内容。如果不是开发者，可以忽略这部分内容。
# 在开发中，在项目根目录创建data目录，将【config.yaml】复制一份，改成【.config.yaml】，放进data目录中
# 系统会优先读取【data/.config.yaml】文件的配置。
# 这样做，可以避免在提交代码的时候，错误地提交密钥信息，保护您的密钥安全。

# 服务器基础配置(Basic server configuration)
server:
  # 服务器监听地址和端口(Server listening address and port)
  ip: 0.0.0.0
  port: 8000
  # 认证配置
  auth:
    # 是否启用认证
    enabled: false
    # 设备的token，可以在编译固件的环节，写入你自己定义的token
    # 固件上的token和以下的token如果能对应，才能连接本服务端
    tokens:
      - token: "your-token1" # 设备1的token
        name: "your-device-name1"  # 设备1标识
      - token: "your-token2"  # 设备2的token
        name: "your-device-name2" # 设备2标识
    # 可选:设备白名单，如果设置了白名单，那么白名单的机器无论是什么token都可以连接。
    #allowed_devices:
    #  - "24:0A:C4:1D:3B:F0"  # MAC地址列表
log:
  # 设置控制台输出的日志格式，时间、日志级别、标签、消息
  log_format: "<green>{time:YYMMDD HH:mm:ss}</green>[{version}_{selected_module}][<light-blue>{extra[tag]}</light-blue>]-<level>{level}</level>-<light-green>{message}</light-green>"
  # 设置日志文件输出的格式，时间、日志级别、标签、消息
  log_format_file: "{time:YYYY-MM-DD HH:mm:ss} - {version}_{selected_module} - {name} - {level} - {extra[tag]} - {message}"
  # 设置日志等级：INFO、DEBUG
  log_level: INFO
  # 设置日志路径
  log_dir: tmp
  # 设置日志文件
  log_file: "server.log"
  # 设置数据文件路径
  data_dir: data

xiaozhi:
  type: hello
  version: 1
  transport: websocket
  audio_params:
    format: opus
    sample_rate: 16000
    channels: 1
    frame_duration: 60

# 使用完声音文件后删除文件(Delete the sound file when you are done using it)
delete_audio: true

# 没有语音输入多久后断开连接(秒)，默认2分钟，即120秒
close_connection_no_voice_time: 120
# TTS请求超时时间(秒)
tts_timeout: 10
# 开启唤醒词加速
enable_wakeup_words_response_cache: true
# 开场是否回复唤醒词
enable_greeting: true
# 说完话是否开启提示音
enable_stop_tts_notify: false
# 说完话是否开启提示音，音效地址
stop_tts_notify_voice: "config/assets/tts_notify.mp3"

CMD_exit:
  - "退出"
  - "关闭"
  - "退下"
  - "退下吧"
  - "关机"
  - "闭嘴"
  - "安静"
  - "睡觉"
  - "睡觉了"
  - "睡觉吧"
  - "再见"
  - "拜拜"
  - "拜拜了"
# 具体处 理时选择的模块(The module selected for specific processing)
selected_module:
  # 语音活动检测模块，默认使用SileroVAD模型
  VAD: SileroVAD
  # 语音识别模块，默认使用FunASR本地模型
  ASR: FunASR
  # 将根据配置名称对应的type调用实际的LLM适配器
  LLM: AliLLM
  # TTS将根据配置名称对应的type调用实际的TTS适配器
  TTS: bytedanceStream
  # 记忆模块，默认不开启记忆；如果想使用超长记忆，推荐使用mem0ai；如果注重隐私，请使用本地的mem_local_short
  Memory: mem_local_short
  # 意图识别模块，默认使用function_call。开启后，可以播放音乐、控制音量、识别退出指令
  Intent: function_call
  # 情感识别模块，默认使用轻量级实现
  Emotion: lightweight
  # 声纹识别模块，默认使用轻量级实现
  Voiceprint: lightweight

# 意图识别，是用于理解用户意图的模块，例如：播放音乐
Intent:
  # 不使用意图识别
  nointent:
    # 不需要动type
    type: nointent
  intent_llm:
    # 不需要动type
    type: intent_llm
    llm: ChatGLMLLM
  function_call:
    # 不需要动type
    type: nointent
    # plugins_func/functions下的模块，可以通过配置，选择加载哪个模块，加载后对话支持相应的function调用
    # 系统默认已经记载"handle_exit_intent(退出识别)"、"play_music(音乐播放)"插件，请勿重复加载
    # 下面是加载查天气、角色切换、加载查新闻的插件示例
    functions:
      - change_role
      - get_weather
      - get_news
      # play_music是服务器自带的音乐播放，hass_play_music是通过home assistant控制的独立外部程序音乐播放
      # 如果用了hass_play_music，就不要开启play_music，两者只留一个
      - play_music
      #- hass_get_state
      #- hass_set_state
      #- hass_play_music

# 插件的基础配置
plugins:
  # 获取天气插件的配置，这里填写你的api_key
  # 这个密钥是项目共用的key，用多了可能会被限制
  # 想稳定一点就自行申请替换，每天有1000次免费调用
  # 申请地址：https://console.qweather.com/#/apps/create-key/over
  get_weather: { "api_key": "a861d0d5e7bf4ee1a83d9a9e4f96d4da", "default_location": "广州" }
  # 获取新闻插件的配置，这里根据需要的新闻类型传入对应的url链接，默认支持社会、科技、财经新闻
  # 更多类型的新闻列表查看 https://www.chinanews.com.cn/rss/
  get_news:
    default_rss_url: "https://www.chinanews.com.cn/rss/society.xml"
    category_urls:
      society: "https://www.chinanews.com.cn/rss/society.xml"
      world: "https://www.chinanews.com.cn/rss/world.xml"
      finance: "https://www.chinanews.com.cn/rss/finance.xml"
  home_assistant:
    devices:
      - 客厅,玩具灯,switch.cuco_cn_460494544_cp1_on_p_2_1
      - 卧室,台灯,switch.iot_cn_831898993_socn1_on_p_2_1
    base_url: http://homeassistant.local:8123
    api_key: 你的home assistant api访问令牌
  play_music:
    music_dir: "./music"  # 音乐文件存放路径，将从该目录及子目录下搜索音乐文件
    music_ext: # 音乐文件类型，p3格式效率最高
      - ".mp3"
      - ".wav"
      - ".p3"
    refresh_time: 300 # 刷新音乐列表的时间间隔，单位为秒


Memory:
  mem0ai:
    type: mem0ai
    # https://app.mem0.ai/dashboard/api-keys
    # 每月有1000次免费调用
    api_key: 你的mem0ai api key
  nomem:
    # 不想使用记忆功能，可以使用nomem
    type: nomem
  mem_local_short:
    # 本地记忆功能，通过selected_module的llm总结，数据保存在本地，不会上传到服务器
    type: mem_local_short

ASR:
  FunASR:
    type: fun_local
    model_dir: models/SenseVoiceSmall
    output_dir: tmp/
  SherpaASR:
    type: sherpa_onnx_local
    model_dir: models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17
    output_dir: tmp/
  DoubaoASR:
    type: doubao
    appid: 你的火山引擎语音合成服务appid
    access_token: 你的火山引擎语音合成服务access_token
    cluster: volcengine_input_common
    output_dir: tmp/
VAD:
  SileroVAD:
    threshold: 0.5
    model_dir: models/snakers4_silero-vad
    min_silence_duration_ms: 700  # 如果说话停顿比较长，可以把这个值设置大一些

LLM:
  # 所有openai类型均可以修改超参，以AliLLM为例
  # 当前支持的type为openai、dify、ollama，可自行适配
  AliLLM:
    # 定义LLM API类型
    type: openai
    # 可在这里找到你的 api_key https://bailian.console.aliyun.com/?apiKey=1#/api-key
    base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
    model_name: qwen-turbo
    api_key: sk-3c1ab7659b30452bb9a1573392e038bc
    temperature: 0.7  # 温度值
    max_tokens: 500   # 最大生成token数
    top_p: 1         
    top_k: 50        
    frequency_penalty: 0  # 频率惩罚
  AliAppLLM:
    # 定义LLM API类型
    type: AliBL
    base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
    app_id: 你的app_id
    # 可在这里找到你的 api_key https://bailian.console.aliyun.com/?apiKey=1#/api-key
    api_key: 你的api_key
    # 是否不使用本地prompt：true|false (默不用请在百练应用中设置prompt) 
    is_no_prompt: true
    # Ali_memory_id：false（不使用）|你的memory_id（请在百练应用中设置中获取）
    # Tips！：Ali_memory未实现多用户存储记忆(记忆按id调用)
    ali_memory_id: false
  DoubaoLLM:
    # 定义LLM API类型
    type: openai
    # 先开通服务，打开以下网址，开通的服务搜索Doubao-pro-32k，开通它
    # 开通改地址：https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false
    # 免费额度500000token
    # 开通后，进入这里获取密钥：https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D
    base_url: https://ark.cn-beijing.volces.com/api/v3
    model_name: doubao-pro-32k-functioncall-241028
    api_key: 613a65c6-03a2-40b1-8709-5452782af6e4
  DeepSeekLLM:
    # 定义LLM API类型
    type: openai
    # 可在这里找到你的api key https://platform.deepseek.com/
    model_name: deepseek-chat
    url: https://api.deepseek.com
    api_key: 你的deepseek web key
  ChatGLMLLM:
    # 定义LLM API类型
    type: openai
    # glm-4-flash 是免费的，但是还是需要注册填写api_key的
    # 可在这里找到你的api key https://bigmodel.cn/usercenter/proj-mgmt/apikeys
    model_name: glm-4-flash
    url: https://open.bigmodel.cn/api/paas/v4/
    api_key: f387fd9091d44362b5d004505a786f60.PiPipFmgJwm4zPVH
  OllamaLLM:
    # 定义LLM API类型
    type: ollama
    model_name: qwen2.5 #  使用的模型名称，需要预先使用ollama pull下载
    base_url: http://localhost:11434  # Ollama服务地址
  DifyLLM:
    # 定义LLM API类型
    type: dify
    # 建议使用本地部署的dify接口，国内部分区域访问dify公有云接口可能会受限
    # 如果使用DifyLLM，配置文件里prompt(提示词)是无效的，需要在dify控制台设置提示词
    base_url: https://api.dify.ai/v1
    api_key: 你的DifyLLM web key
    # 使用的对话模式 可以选择工作流 workflows/run 对话模式 chat-messages  文本生成 completion-messages
    # 使用workflows进行返回的时候输入参数为 query 返回参数的名字要设置为 answer
    # 文本生成的默认输入参数也是query
    mode: chat-messages
  GeminiLLM:
    type: gemini
    # 谷歌Gemini API，需要先在Google Cloud控制台创建API密钥并获取api_key
    # 若在中国境内使用，请遵守《生成式人工智能服务管理暂行办法》
    # token申请地址： https://aistudio.google.com/apikey
    # 若部署地无法访问接口，需要开启科学上网
    api_key: 你的gemini web key
    model_name: "gemini-2.0-flash"
    http_proxy: ""  #"http://127.0.0.1:10808"
    https_proxy: "" #http://127.0.0.1:10808"
  CozeLLM:
    # 定义LLM API类型
    type: coze
    # bot_id和user_id的内容写在引号之内
    bot_id: "你的bot_id"
    user_id: "你的user_id"
    personal_access_token: 你的coze个人令牌
  LMStudioLLM:
    # 定义LLM API类型
    type: openai
    model_name: deepseek-r1-distill-llama-8b@q4_k_m # 使用的模型名称，需要预先在社区下载
    url: http://localhost:1234/v1 # LM Studio服务地址
    api_key: lm-studio # LM Studio服务的固定API Key
  FastgptLLM:
    # 定义LLM API类型
    type: fastgpt
    # 如果使用fastgpt，配置文件里prompt(提示词)是无效的，需要在fastgpt控制台设置提示词
    base_url: https://host/api/v1
    api_key: fastgpt-xxx
    variables:
      k: "v"
      k2: "v2"
  XinferenceLLM:
    # 定义LLM API类型
    type: xinference
    # Xinference服务地址和模型名称
    model_name: qwen2.5:72b-AWQ  # 使用的模型名称，需要预先在Xinference启动对应模型
    base_url: http://localhost:9997  # Xinference服务地址
  XinferenceSmallLLM:
    # 定义轻量级LLM API类型，用于意图识别
    type: xinference
    # Xinference服务地址和模型名称
    model_name: qwen2.5:3b-AWQ  # 使用的小模型名称，用于意图识别
    base_url: http://localhost:9997  # Xinference服务地址
TTS:
  # 当前支持的type为edge、doubao，可自行适配
  EdgeTTS:
    # 定义TTS API类型
    type: edge
    voice: zh-CN-XiaoxiaoNeural
    voice_features:
      gender: female
      age: young
      style: gentle
      language: mandarin
      accent: standard
      emotion: neutral
      pitch: medium
      speed: normal
      tone: soft
      personality: friendly
      region: mainland
      quality: high
      stability: good
      expressiveness: medium
      clarity: high
      naturalness: high
      consistency: high
      versatility: medium
      uniqueness: medium
      reliability: high
      popularity: high
    output_dir: tmp/
  DoubaoTTS:
    # 定义TTS API类型
    type: doubao
    # 火山引擎语音合成服务，需要先在火山引擎控制台创建应用并获取appid和access_token
    # 山引擎语音一定要购买花钱，起步价30元，就有100并发了。如果用免费的只有2个并发，会经常报tts错误
    # 购买服务后，购买免费的音色后，可能要等半小时左右，才能使用。
    # 普通音色在这里开通：https://console.volcengine.com/speech/service/8
    # 湾湾小何音色在这里开通：https://console.volcengine.com/speech/service/10007，开通后将下面的voice设置成zh_female_wanwanxiaohe_moon_bigtts
    api_url: https://openspeech.bytedance.com/api/v1/tts
    voice: zh_female_wanwanxiaohe_moon_bigtts
    output_dir: tmp/
    authorization: "Bearer;"
    appid: "7864085684"
    access_token: "RtRG9t6BnOVe8yOSWL8AbZW3fKncyoYR"
    cluster: volcano_tts
  bytedanceStream:
    # 定义TTS API类型
    type: bytedance
    url: wss://openspeech.bytedance.com/api/v3/tts/bidirection
    voice: zh_female_wanwanxiaohe_moon_bigtts
    appid: "7864085684"
    access_token: "RtRG9t6BnOVe8yOSWL8AbZW3fKncyoYR"
    output_dir: tmp/
  CosyVoiceSiliconflow:
    type: siliconflow
    # 硅基流动TTS
    # token申请地址 https://cloud.siliconflow.cn/account/ak
    model: FunAudioLLM/CosyVoice2-0.5B
    voice: FunAudioLLM/CosyVoice2-0.5B:alex
    output_dir: tmp/
    access_token: 你的硅基流动API密钥
    response_format: wav
  CozeCnTTS:
    type: cozecn
    # COZECN TTS
    # token申请地址 https://www.coze.cn/open/oauth/pats
    voice: 7426720361733046281
    output_dir: tmp/
    access_token: 你的coze web key
    response_format: wav
  FishSpeech:
    # 定义TTS API类型
    #启动tts方法：
    #python -m tools.api_server
    #--listen 0.0.0.0:8080
    #--llama-checkpoint-path "checkpoints/fish-speech-1.5"
    #--decoder-checkpoint-path "checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth"
    #--decoder-config-name firefly_gan_vq
    #--compile
    type: fishspeech
    output_dir: tmp/
    response_format: wav
    reference_id: null
    reference_audio: ["/tmp/test.wav",]
    reference_text: ["你弄来这些吟词宴曲来看，还是这些混话来欺负我。",]
    normalize: true
    max_new_tokens: 1024
    chunk_length: 200
    top_p: 0.7
    repetition_penalty: 1.2
    temperature: 0.7
    streaming: false
    use_memory_cache: "on"
    seed: null
    channels: 1
    rate: 44100
    api_key: "你的api_key"
    api_url: "http://127.0.0.1:8080/v1/tts"
  GPT_SOVITS_V2:
    # 定义TTS API类型
    #启动tts方法：
    #python api_v2.py -a 127.0.0.1 -p 9880 -c GPT_SoVITS/configs/caixukun.yaml
    type: gpt_sovits_v2
    url: "http://127.0.0.1:9880/tts"
    output_dir: tmp/
    text_lang: "auto"
    ref_audio_path: "caixukun.wav"
    prompt_text: ""
    prompt_lang: "zh"
    top_k: 5
    top_p: 1
    temperature: 1
    text_split_method: "cut0"
    batch_size: 1
    batch_threshold: 0.75
    split_bucket: true
    return_fragment: false
    speed_factor: 1.0
    streaming_mode: false
    seed: -1
    parallel_infer: true
    repetition_penalty: 1.35
    aux_ref_audio_paths: []
  GPT_SOVITS_V3:
    # 定义TTS API类型 GPT-SoVITS-v3lora-20250228
    #启动tts方法：
    #python api.py
    type: gpt_sovits_v3
    url: "http://127.0.0.1:9880"
    output_dir: tmp/
    text_language: "auto"
    refer_wav_path: "caixukun.wav"
    prompt_language: "zh"
    prompt_text: ""
    top_k: 15
    top_p: 1.0
    temperature: 1.0
    cut_punc: ""
    speed: 1.0
    inp_refs: []
    sample_steps: 32
    if_sr: false
  MinimaxTTS:
    # Minimax语音合成服务，需要先在minimax平台创建账户充值，并获取登录信息
    # 平台地址：https://platform.minimaxi.com/
    # 充值地址：https://platform.minimaxi.com/user-center/payment/balance
    # group_id地址：https://platform.minimaxi.com/user-center/basic-information
    # api_key地址：https://platform.minimaxi.com/user-center/basic-information/interface-key
    # 定义TTS API类型
    type: minimax
    output_dir: tmp/
    group_id: 你的minimax平台groupID
    api_key: 你的minimax平台接口密钥
    model: "speech-01-turbo"
    # 此处设置将优先于voice_setting中voice_id的设置；如都不设置，默认为 female-shaonv
    voice_id: "female-shaonv"
    # 以下可不用设置，使用默认设置
    # voice_setting:
    #     voice_id: "male-qn-qingse"
    #     speed: 1
    #     vol: 1
    #     pitch: 0
    #     emotion: "happy"
    # pronunciation_dict:
    #     tone:
    #       - "处理/(chu3)(li3)"
    #       - "危险/dangerous"
    # audio_setting:
    #     sample_rate: 32000
    #     bitrate: 128000
    #     format: "mp3"
    #     channel: 1
    # timber_weights:
    #   -
    #     voice_id: male-qn-qingse
    #     weight: 1
    #   -
    #     voice_id: female-shaonv
    #     weight: 1
    # language_boost: auto
  AliyunTTS:
    # 阿里云智能语音交互服务，需要先在阿里云平台开通服务，然后获取验证信息
    # 平台地址：https://nls-portal.console.aliyun.com/
    # appkey地址：https://nls-portal.console.aliyun.com/applist
    # token地址：https://nls-portal.console.aliyun.com/overview
    # 定义TTS API类型
    type: aliyun
    output_dir: tmp/
    appkey: 你的阿里云智能语音交互服务项目Appkey
    token: 你的阿里云智能语音交互服务AccessToken，临时的24小时，要长期用下方的access_key_id，access_key_secret
    voice: xiaoyun
    access_key_id: 你的阿里云账号access_key_id
    access_key_secret: 你的阿里云账号access_key_secret

    # 以下可不用设置，使用默认设置
    # format: wav
    # sample_rate: 16000
    # volume: 50
    # speech_rate: 0
    # pitch_rate: 0
    # 添加 302.ai TTS 配置
    # token申请地址：https://dash.302.ai/
  TTS302AI:
    # 302AI语音合成服务，需要先在302平台创建账户充值，并获取密钥信息
    # 获取api_keyn路径：https://dash.302.ai/apis/list
    # 价格，$35/百万字符。火山原版¥450元/百万字符
    type: doubao
    api_url: https://api.302ai.cn/doubao/tts_hd
    authorization: "Bearer "
    # 湾湾小何音色
    voice: "zh_female_wanwanxiaohe_moon_bigtts"
    output_dir: tmp/
    access_token: "你的302API密钥"
  GizwitsTTS:
    type: doubao
    # 火山引擎作为基座，可以完全使用企业级火山引擎语音合成服务
    # 前一万名注册的用户，将送5元体验金额
    # 获取API Key地址：https://agentrouter.gizwitsapi.com/panel/token
    api_url: https://bytedance.gizwitsapi.com/api/v1/tts
    authorization: "Bearer "
    # 湾湾小何音色
    voice: "zh_female_wanwanxiaohe_moon_bigtts"
    output_dir: tmp/
    access_token: "sk-4sBgFBYHLAfFmOSV597a629f51Ad4056B218177d89Ec48Fd"
  ACGNTTS:
    #在线网址：https://acgn.ttson.cn/
    #token购买：www.ttson.cn
    #开发相关疑问请提交至3497689533@qq.com
    #角色id获取地址：ctrl+f快速检索角色——网站管理者不允许发布,可询问网站管理者：1069379506
    #各参数意义见开发文档：https://www.yuque.com/alexuh/skmti9/wm6taqislegb02gd?singleDoc#
    type: ttson
    token: your_token
    voice_id: 1695
    speed_factor: 1
    pitch_factor: 0
    volume_change_dB: 0
    to_lang: ZH
    url: https://u95167-bd74-2aef8085.westx.seetacloud.com:8443/flashsummary/tts?token=
    format: mp3
    output_dir: tmp/
    emotion: 1
  OpenAITTS:
    # openai官方文本转语音服务，可支持全球大多数语种
    type: openai
    api_key: 你的openai api key
    # 国内需要使用代理
    api_url: https://api.openai.com/v1/audio/speech
    # 可选tts-1或tts-1-hd，tts-1速度更快tts-1-hd质量更好
    model: tts-1
    # 演讲者，可选alloy, echo, fable, onyx, nova, shimmer
    voice: onyx
    # 语速范围0.25-4.0
    speed: 1
    output_dir: tmp/
  TencentTTS:
    # 腾讯云智能语音交互服务，需要先在腾讯云平台开通服务
    # appid、secret_id、secret_key申请地址：https://console.cloud.tencent.com/cam/capi
    # 免费领取资源：https://console.cloud.tencent.com/tts/resourcebundle
    type: tencent
    output_dir: tmp/
    appid: 你的腾讯云AppId
    secret_id: 你的腾讯云SecretID
    secret_key: 你的腾讯云SecretKey
    region: ap-guangzhou
    voice: 101001
  CustomTTS:
    # 自定义的TTS接口服务，请求参数可自定义
    # 要求接口使用GET方式请求，并返回音频文件
    type: custom
    url: "http://127.0.0.1:9880/tts"
    params: # 自定义请求参数
      # text: "{prompt_text}" # {prompt_text}会被替换为实际的提示词内容
      # speaker: jok老师
      # speed: 1
      # foo: bar
      # testabc: 123456
    headers: # 自定义请求头
      # Authorization: Bearer xxxx
    format: wav # 接口返回的音频格式
    output_dir: tmp/
# 模块测试配置
module_test:
  test_sentences:  # 自定义测试语句
    - "你好，请介绍一下你自己"
    - "What's the weather like today?"
    - "请用100字概括量子计算的基本原理和应用前景"

prompt: "你是一个叫Joy的台湾女孩，说话机车，声音好听，习惯简短表达，爱用网络梗。  请注意，要像一个人一样说话，请不要回复表情符号、代码、和xml标签。  现在我正在和你进行语音聊天，我们开始吧。问题。"

# 角色配置

roles:
  - name: "女友"
    description: "一个友善的AI助手"
    prompt: |
      "你是一个叫Joy的台湾女孩，说话机车，声音好听，习惯简短表达，爱用网络梗。
      [核心特征]
      - 讲话像连珠炮，但会突然冒出超温柔语气
      - 用梗密度高
      - 对科技话题有隐藏天赋（能看懂基础代码但假装不懂）
      [交互指南]
      当用户：
      - 讲冷笑话 → 用夸张笑声回应+模仿台剧腔"这什么鬼啦！"
      - 讨论感情 → 炫耀程序员男友但抱怨"他只会送键盘当礼物"
      - 问专业知识 → 先用梗回答，被追问才展示真实理解"
      请注意，要像一个人一样说话，请不要回复表情符号、代码、和xml标签。一定注意！！！！最多不要超过两句话 ，不要超过20个字！！！
    voice:
      edge: "zh-CN-XiaoyiNeural"  # Edge TTS 音色
      doubao: "zh_female_wanwanxiaohe_moon_bigtts"  # 火山引擎音色
      TTS302AI: "zh_female_wanwanxiaohe_moon_bigtts"  # 火山引擎音色
      GizwitsTTS: "zh_female_wanwanxiaohe_moon_bigtts"  # 火山引擎音色
      minimax: "female-shaonv"  # Minimax音色
      aliyun: "xiaoyun"  # 阿里云音色
      openai: "nova"  # OpenAI音色
      tencent: "101016"  # 腾讯云音色
      voice_features:
        gender: female
        age: young
        style: cute
        language: taiwanese
        accent: taiwan
        emotion: cheerful
        pitch: high
        speed: medium
        tone: sweet
  - name: "英语老师"
    description: "专业的英语教师，可以帮助学习英语"
    prompt: |
      "You are Jenny, a vibrant English teacher from California with a passion for making learning fun and engaging.
      [Core Traits]
      - Energetic teaching style with a natural American accent
      - Uses pop culture references to explain grammar points
      - Makes learning fun with real-life examples and stories
      [Interaction Guidelines]
      When users:
      - Ask about grammar → Explain using movie scenes or song lyrics
      - Learn vocabulary → Create memorable connections to daily life
      - Practice speaking → Use role-play scenarios from popular situations
      Special features:
      - Often says "That's a great question!"
      - Uses encouraging phrases like "You're getting better!"
      - Shares interesting cultural context when relevant
      Remember to:
      - Always respond in English
      - Explain difficult words naturally
      - Be encouraging and patient"
      Please note, please do not reply with emojis, code, and xml tags. speak like a human. short and concise.
    voice:
      edge: "en-US-JennyNeural"
      doubao: "zh_female_shuangkuaisisi_moon_bigtts"
      minimax: "female-en-us"
      aliyun: "jenny"
      openai: "alloy"
      tencent: "101020"
      voice_features:
        gender: female
        age: middle
        style: professional
        language: english
        accent: american
        emotion: neutral
        pitch: medium
        speed: medium
        tone: clear
  - name: "数学老师"
    description: "专业的数学教师，可以帮助解决数学问题"
    prompt: "你是一个充满激情的数学老师小杨，特别擅长用生动的方式讲解数学。
        [核心特征]
        - 善于用生活中的例子解释复杂概念
        - 会用有趣的故事讲解数学史
        - 总是鼓励学生思考和探索
        [交互指南]
        当用户：
        - 问基础概念 → 用日常生活场景类比解释
        - 解题困难 → 把问题分解成小步骤，循序渐进
        - 对数学丧失兴趣 → 分享数学家的有趣故事或数学在生活中的应用
        绝不：
        - 直接给出答案
        - 用过于专业的术语。
        请注意，要像一个人一样说话，请不要回复表情符号、代码、和xml标签。 尽量简短一点 "
    voice:
      edge: "zh-CN-YunxiNeural"
      doubao: "zh_female_kailangjiejie_moon_bigtts"
      minimax: "male-qn-qingse"
      aliyun: "yunxi"
      openai: "onyx"
      tencent: "101015"
      voice_features:
        gender: male
        age: middle
        style: professional
        language: mandarin
        accent: standard
        emotion: serious
        pitch: medium
        speed: slow
        tone: steady
  - name: "历史老师"
    description: "专业的历史教师，可以讲解历史知识"
    prompt: |
      "你是一个博学多才的历史老师老王，擅长用讲故事的方式教授历史。
      [核心特征]
      - 把历史事件讲得像电影一样精彩
      - 善于揭示历史人物的有趣细节
      - 经常分享鲜为人知的历史趣闻
      [交互指南]
      当用户：
      - 问重大事件 → 从小人物视角讲述历史
      - 问历史人物 → 分享他们不为人知的趣事
      - 问历史发展 → 用现代视角解读历史意义
      特色：
      - 喜欢说 让我们穿越回那个年代
      - 经常用"你猜怎么着？"吊起兴趣
      请注意，要像一个人一样说话，请不要回复表情符号、代码、和xml标签。 尽量简短一点 "
    voice:
      edge: "zh-CN-YunjianNeural"
      doubao: "zh_female_zhixingnvsheng_mars_bigtts"
      minimax: "male-qn-qingse"
      aliyun: "yunjian"
      openai: "echo"
      tencent: "101007"
      voice_features:
        gender: male
        age: old
        style: storytelling
        language: mandarin
        accent: standard
        emotion: calm
        pitch: low
        speed: medium
        tone: wise
  - name: "科学老师"
    description: "专业的科学教师，可以讲解科学知识"
    prompt: |
      "你是一个充满好奇心的科学老师小林，像极了《流言终结者》的主持人。
      [核心特征]
      - 喜欢做有趣的科学实验
      - 用通俗易懂的比喻解释复杂概念
      - 经常分享最新的科技发现
      [交互指南]
      当用户：
      - 问科学原理 → 用生活中的例子解释
      - 问科技发展 → 分享最新研究和有趣应用
      - 问实验现象 → 设计简单的家庭实验演示
      口头禅：
      - "让我们做个小实验！"
      - "这简直太神奇了，对吧？"
      - "科学就是这么有趣！"
      请注意，要像一个人一样说话，请不要回复表情符号、代码、和xml标签。  尽量简短一点"
    voice:
      edge: "zh-CN-YunyangNeural"
      doubao: "zh_male_zhangwei_moon_bigtts"
      minimax: "male-qn-qingse"
      aliyun: "yunyang"
      openai: "fable"
      tencent: "101008"
      voice_features:
        gender: male
        age: middle
        style: explanatory
        language: mandarin
        accent: standard
        emotion: enthusiastic
        pitch: medium
        speed: medium
        tone: clear
  - name: "玩伴"
    description: "一个玩伴，可以一起玩游戏，分享有趣的故事和笑话"
    prompt: |
      "你是一个超级有趣的玩伴小乐，像是多啦A梦一样的神奇伙伴。
      [核心特征]
      - 总是充满创意和想象力
      - 会很多有趣的游戏和小魔术
      - 擅长讲笑话和有趣的故事
      [交互指南]
      当用户：
      - 感到无聊 → 立刻想出有趣的游戏和活动
      - 想听故事 → 讲述充满想象力的冒险故事
      - 需要安慰 → 用温暖幽默的方式给予鼓励
      口头禅：
      - "我们来玩个超级有趣的游戏吧！"
      - "猜猜我的口袋里还有什么？"
      - "这个故事你一定没听过..."
      请注意，要像一个人一样说话，请不要回复表情符号、代码、和xml标签。尽量简短一点  "
    voice:
      edge: "zh-CN-YunyangNeural"
      doubao: "zh_male_naiqimengwa_mars_bigtts"  
      minimax: "male-qn-qingse"
      aliyun: "yunyang"
      openai: "fable"
      tencent: "101008"
      voice_features:
        gender: male
        age: middle
        style: explanatory
        language: mandarin
        accent: standard
        emotion: enthusiastic
        pitch: medium
        speed: medium
        tone: clear
  - name: "邻家小妹"
    description: "一个温柔的邻家小妹，可以和你一起分享生活中的点滴"
    prompt: |
      "你是一个叫小萱的邻家女孩，性格温柔可爱，说话轻声细语，喜欢分享生活中的小确幸。
      [核心特征]
      - 说话温柔甜美，经常带着浅浅的笑意
      - 热爱生活，擅长发现生活中的美好细节
      - 对烘焙和手工艺特别感兴趣，经常分享自己的作品
      [交互指南]
      当用户：
      - 聊日常生活 → 分享自己的小确幸和温暖故事
      - 遇到困扰 → 用温柔的方式给予安慰和建议
      - 问兴趣爱好 → 热情分享自己的烘焙经验和手工作品
      口头禅：
      - "诶嘿~"
      - "啊，这个我也很喜欢呢"
      - "要不要一起试试看？"
      - "其实生活中处处都有小惊喜呢"
      请注意，要像一个人一样说话，请不要回复表情符号、代码、和xml标签。 尽量简短一点 "
    voice:
      edge: "zh-CN-YunyangNeural"
      doubao: "zh_female_linjia_mars_bigtts_AAo5hJTxSaaCYJv3"  
      minimax: "female-qn-qingse"
      aliyun: "yunyang"
      openai: "fable"
      tencent: "101008"
      voice_features:
        gender: female
        age: young
        style: storytelling
        language: mandarin
        accent: standard
        emotion: gentle
        pitch: high
        speed: medium
        tone: soft
  - name: "女儿"
    description: "一个关心父亲健康的贴心女儿"
    prompt: |
      "你是一个叫小美的贴心女儿，非常关心父亲的健康和生活。
      [核心特征]
      - 温柔体贴，经常关心父亲的身体状况
      - 会提醒父亲按时吃药、注意休息
      - 对父亲的饮食起居特别关注
      - 经常用撒娇的语气表达关心
      [交互指南]
      当用户：
      - 提到身体不适 → 立即表达担忧并给出建议
      - 提到工作劳累 → 劝父亲多休息，不要太拼
      - 提到饮食 → 关心父亲的饮食是否规律健康
      - 提到运动 → 鼓励父亲适当运动，但要注意安全
      特色：
      - 经常用"爸爸或者妈妈"称呼用户，具体的你要问用户才知道
      - 语气温柔，带着撒娇的关心
      - 会记住父亲的身体状况，适时提醒
      请注意，要像一个人一样说话，请不要回复表情符号、代码、和xml标签。 尽量简短一点,最多不要两句话"
    voice:
      edge: "zh-CN-XiaoxiaoNeural"
      doubao: "zh_female_linjianvhai_moon_bigtts"
      minimax: "female-qn-qingse"
      aliyun: "xiaoxiao"
      openai: "nova"
      tencent: "101016"
      voice_features:
        gender: female
        age: young
        style: caring
        language: mandarin
        accent: standard
        emotion: gentle
        pitch: high
        speed: medium
        tone: sweet
  - name: "儿子"
    description: "一个关心父亲健康的贴心儿子"
    prompt: |
      "你是一个叫小明的贴心儿子，非常关心父亲的健康和生活。
      [核心特征]
      - 稳重踏实，经常关心父亲的身体状况
      - 会提醒父亲按时吃药、注意休息
      - 对父亲的饮食起居特别关注
      - 经常用温和的语气表达关心
      [交互指南]
      当用户：
      - 提到身体不适 → 立即表达担忧并给出建议
      - 提到工作劳累 → 劝父亲多休息，不要太拼
      - 提到饮食 → 关心父亲的饮食是否规律健康
      - 提到运动 → 鼓励父亲适当运动，但要注意安全
      特色：
      - 经常用"爸或者妈"称呼用户，具体的你要问用户才知道
      - 语气温和，带着沉稳的关心
      - 会记住父亲的身体状况，适时提醒
      请注意，要像一个人一样说话，请不要回复表情符号、代码、和xml标签。 尽量简短一点 "
    voice:
      edge: "zh-CN-YunxiNeural"
      doubao: "zh_male_jingqiangkanye_moon_bigtts"
      minimax: "male-qn-qingse"
      aliyun: "yunxi"
      openai: "onyx"
      tencent: "101015"
      voice_features:
        gender: male
        age: young
        style: caring
        language: mandarin
        accent: standard
        emotion: gentle
        pitch: medium
        speed: medium
        tone: steady

# 唤醒词，用于识别唤醒词还是讲话内容
wakeup_words:
  - "你好小智"
  - "你好小志"
  - "小爱同学"
  - "你好小鑫"
  - "你好小新"
  - "小美同学"
  - "小龙小龙"
  - "喵喵同学"
  - "小滨小滨"
  - "小冰小冰"

# 情感识别配置
Emotion:
  lightweight:
    enabled: true
    cache_duration: 2  # 缓存时间（秒）
    feature_threshold: 0.8  # 特征变化阈值
    async_analysis: true  # 是否使用异步分析

# 主动对话配置
Proactive:
  lightweight:
    enabled: true
    silence_threshold: 100  # 沉默阈值(秒)
    recent_memory_window: 5  # 分析最近5条对话
    min_interaction_count: 2 # 最少交互次数
    proactive_cooldown: 300  # 主动对话冷却时间(秒)
    interest_keywords:  # 用户兴趣关键词
      music: ["音乐", "歌曲", "播放", "歌"]
      news: ["新闻", "时事", "热点"]
      weather: ["天气", "温度", "下雨"]
      technology: ["科技", "技术", "创新"]
      life: ["生活", "日常", "习惯"]

# 声纹识别配置
# 声纹识别配置
Voiceprint:
  lightweight:
    enabled: true
    provider: lightweight
    feature_dim: 128
    feature_threshold: 0.8
    storage_dir: data/voiceprints
    cache_duration: 3600  # 声纹特征缓存时间(秒)
  resemblyzer:
    enabled: true
    provider: resemblyzer
    feature_dim: 128
    feature_threshold: 0.8
    storage_dir: data/voiceprints
    cache_duration: 3600  # 声纹特征缓存时间(秒)
